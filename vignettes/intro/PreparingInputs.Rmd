---
title: "Preparing model inputs"
author: "Miquel De CÃ¡ceres"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: TRUE
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## About this article

A companion article [*Understanding model inputs*](https://emf-creaf.github.io/medfate/articles/intro/UnderstandingInputs.html) explained the vegetation, soil and weather structures needed to run the simulation models included in **medfate**. Preparing inputs for simulations with **medfate** is not straightforward, because it requires obtaining and reshaping data for vegetation, soil and weather. Therefore, this article illustrates some common issues that arise in the process of preparing inputs, so that the user is aware of them when processing his/her own data.

We begin by loading packages **medfate** and **meteoland**:

```{r}
library(medfate)
library(meteoland)
```

## Building/manipulating forest objects

In this section we show how to build and manipulate objects of class `forest`, for their use in package medfate, starting from a table containing forest inventory data.

### Poblet tree data set

Package **medfate** includes a small dataset of tree data, corresponding to a dense holm oak forest in Poblet (Catalonia, Spain). As a result of the abandonment of previous coppicing exploitation, there is a high density of stems per individual.

We begin by loading the tree data from Poblet:

```{r}
data("poblet_trees")
```

and we inspect its content, for example using:

```{r}
summary(poblet_trees)
```

The data frame includes tree data corresponding to three forest inventories:

```{r}
table(poblet_trees$Plot.Code)
```

`POBL_CTL` corresponds to an oak forest where no treatment was done (control), whereas `POBL_THI_BEF` and `POBL_THI_AFT` are two forest inventories conducted on the same forest plot, before and after a thinning intervention to reduce the number of stems.

### Mapping trees from the control forest

We initialize an empty forest object using function `emptyforest()` from package **medfate**:

```{r}
pobl_ctl <- emptyforest()
pobl_ctl
```

Now we will fill in data for element `treeData` in the `forest` object. For that, we need to define a mapping from column names in `poblet_trees` to variables in `treeData`. The mapping can be defined using a **named string vector**, i.e. a vector where element names are variable names in `treeData` and vector elements are strings of the variable names in `poblet_trees`:

```{r}
mapping <- c("Species.name" = "Species", "DBH" = "Diameter.cm")
```

We can now replace the empty `treeData` in `pobl_ctl` using functions `subset()` and `forest_mapTreeTable()`:

```{r}
pobl_ctl$treeData <- forest_mapTreeTable(subset(poblet_trees, Plot.Code=="POBL_CTL"), 
                                         mapping_x = mapping, SpParams = SpParamsMED)
```

We can inspect the result using:

```{r}
summary(pobl_ctl$treeData)
```

Some data are missing, but we will not worry about it now. One way to evaluate if the tree data is correctly specified is to display a summary of the `forest` object using the `summary` function defined in **medfate** for this object class:

```{r}
summary(pobl_ctl, SpParamsMED)
```

The values of stand density and stand basal area are too low for such a dense forest, which indicates that something needs to be corrected. At this point, it is important to remember that `forest` objects need the density of trees to be specified as *stems per hectare*. We conducted our tree data mapping without indicating the area of the sampled plot. We are told that forest stand sampling was done using a circular plot whose radius was 15 m. We can calculate the sampled area using:

```{r}
sampled_area <- pi*15^2
```

and use this information to map the tree data again, where we specify parameter `plot_size_x`:

```{r}
pobl_ctl$treeData <- forest_mapTreeTable(subset(poblet_trees, Plot.Code=="POBL_CTL"),
                                         mapping_x = mapping, SpParams = SpParamsMED, 
                                         plot_size_x = sampled_area)
```

We run again the summary:

```{r}
summary(pobl_ctl, SpParamsMED)
```

which results in a much higher basal area and density, as should be expected for a dense oak forest resulting from an abandoned old coppice.

Another issue that we see is the percentage of PAR and SWR that reaches the ground, which have missing values. This indicates that medfate cannot calculate the light extinction profile, in our case because tree heights are missing. Thus, we should somehow estimate tree heights, for example using an allometric relationship:

```{r}
poblet_trees$Height.cm <- 100 * 1.806*poblet_trees$Diameter.cm^0.518
summary(poblet_trees$Height.cm)
```

So trees are between 5 and 10 m height. Once tree heights are defined, we can include them in our mapping:

```{r}
mapping = c("Species.name" = "Species", "DBH" = "Diameter.cm", "Height" = "Height.cm")
```

and rerun the tree data mapping:

```{r}
pobl_ctl$treeData <- forest_mapTreeTable(subset(poblet_trees, Plot.Code=="POBL_CTL"),
                                         mapping_x = mapping, SpParams = SpParamsMED, 
                                         plot_size_x = sampled_area)
```

Now the summary of the control forest stand looks like:

```{r}
summary(pobl_ctl, SpParamsMED)
```

The fraction of PAR/SWR reaching the ground is low, as would be expected for a dense forest.

### Mapping trees from the managed forest

Here we can repeat our mapping for the managed forest plot, which has two codes corresponding to before and after the thinning intervention. Let us first address the pre-thinning state:

```{r}
pobl_thi_bef  <- emptyforest()
pobl_thi_bef$treeData <- forest_mapTreeTable(subset(poblet_trees, Plot.Code=="POBL_THI_BEF"),
                                             mapping_x = mapping, SpParams = SpParamsMED, 
                                             plot_size_x = sampled_area)
```

A warning is raised that not all species names could be parsed. In this case, the reason is that the name used for the downy oak (*Quercus humilis*) is a synonym and needs to be replaced by its accepted name (*Quercus pubescens*), which we can do:

```{r}
poblet_trees$Species[poblet_trees$Species=="Quercus humilis"] <- "Quercus pubescens"
```

Now we repeat our mapping:

```{r}
pobl_thi_bef$treeData <- forest_mapTreeTable(subset(poblet_trees, Plot.Code=="POBL_THI_BEF"),
                                             mapping_x = mapping, SpParams = SpParamsMED, 
                                             plot_size_x = sampled_area)

summary(pobl_thi_bef, SpParamsMED)
```

Like the control plot, these statistics indicate a dense oak forest. We can repeat the same operations with the forest plot after the thinning intervention:

```{r}
pobl_thi_aft = emptyforest()
pobl_thi_aft$treeData <- forest_mapTreeTable(subset(poblet_trees, Plot.Code=="POBL_THI_AFT"),
                                             mapping_x = mapping, SpParams = SpParamsMED, 
                                             plot_size_x = sampled_area)
summary(pobl_thi_aft, SpParamsMED)
```

Note the decrease in tree density and basal area, and the increase in light reaching the ground, despite the estimated leaf area index is still high.

### Reducing the number of woody cohorts

So far we have considered that each tree record should correspond to a woody cohort. We can check the number of tree cohorts in each `forest` structure using:

```{r}
nrow(pobl_ctl$treeData)
nrow(pobl_thi_bef$treeData)
nrow(pobl_thi_aft$treeData)
```

This large amount of cohorts can slow done simulations considerably. Hence, it is advisable to lump them into coarser woody cohorts. One way of doing this is via function `forest_mergeTrees()` from package **medfate**:

```{r}
pobl_ctl <- forest_mergeTrees(pobl_ctl)
pobl_thi_bef <- forest_mergeTrees(pobl_thi_bef)
pobl_thi_aft <- forest_mergeTrees(pobl_thi_aft)
```

By default, the function will pool tree cohorts of the same species and diameter class (defined every 5 cm). We can check the new number of tree cohorts using again:

```{r}
nrow(pobl_ctl$treeData)
nrow(pobl_thi_bef$treeData)
nrow(pobl_thi_aft$treeData)
```

We can check whether stand properties were altered using the `summary()` function:

```{r}
summary(pobl_thi_aft, SpParamsMED)
```

Function `forest_mergeTrees()` will preserve the stand density and basal area that the stand description had before merging cohorts. Other properties like leaf area index may be slightly modified.

In general, it is advisable to reduce the number of woody cohorts before running simulation models in **medfate**.

## Retrieving SoilGrids data

Because soil properties vary strongly at fine spatial scales, ideally soil physical attributes should be measured on samples taken at the forest stand to be simulated. For those users lacking such data, soil properties modelled at larger scales are available via SoilGrids.org.

Retrieval of soil properties from SoilGrids can be done using function `add_soilgrids()` from package **medfateland**. Assuming we know the plot coordinates, we first create an object `sf` (see package **sf**):
```{r}
sf_pt <- sf::st_sfc(sf::st_point(c(1.0219, 41.3443)), crs = 4326)
```

With this function we will obtain, for each location, a data frame of soil properties:

```{r, include = FALSE}
pobl_soil_props <- readRDS("pobl_soil_props.rds")
```

```{r}
pobl_soil_props
```
This data frame is a physical description of the soil. Initialization of additional parameters and state variables is done using function `soil()`:

```{r}
pobl_soil <- soil(pobl_soil_props)
```

We can inspect the soil definition using:

```{r}
print(pobl_soil)
```
It is important to remember that SoilGrids may underestimate the amount of rocks in the soil. This is because soil samples (which were used to generate the global database) do not normally contain large stones or blocks. Hence, realistic simulations should reduce the soil water holding capacity by increasing the column `rfc`. For example, here we will assume that the third layer contains 80% of rocks:

```{r}
pobl_soil_props$rfc[3] <- 80
```

If we rebuild the soil object and inspect its properties we will see the effect on the soil water holding capacity and soil extractable water:

```{r}
pobl_soil <- soil(pobl_soil_props)
print(pobl_soil)
```

## Interpolating weather

While soil information is often scarce and uncertain, obtaining daily weather data suitable for simulations is not straightforward either. Here we illustrate one way of obtaining such data using package **meteoland**. We begin by adding topographic variables into a `sf` object:

```{r}
pobl_spt <- sf::st_sf(sf_pt) |>
            dplyr::mutate(elevation = 850,
                          slope = 15.1, 
                          aspect = 15)

pobl_spt
```

The more difficult part of using package **meteoland** is to assemble reference weather data from surface weather stations into the socalled **interpolator** object (of class `stars`). Please see the [meteoland package documentation](https://emf-creaf.github.io/meteoland/index.html) to learn how to create interpolator objects. Here we will assume that such an object is already available, by using the example object provided in the **meteoland** package.

```{r}
data("meteoland_interpolator_example")
```

Once we have this interpolator, obtaining interpolated weather for a set of target points is rather straightforward using function `interpolate_data()` from **meteoland**:

```{r}
meteo <- interpolate_data(pobl_spt, meteoland_interpolator_example)
```

 The output of function `interpolate_data()` is an object of class `sf`:

```{r}
meteo
```

We can access the weather data frame by subsetting the appropriate element of `interpolated_data`:

```{r}
pobl_weather <- meteo$interpolated_data[[1]]
head(pobl_weather)
```
